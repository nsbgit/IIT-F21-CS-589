{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of naive Bayes and logistic regression for text categorization\n",
    "\n",
    "Adapted from https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load subset of \"20 Newsgroups\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"misc.forsale\", \"sci.space\", \n",
    "              \"sci.electronics\", \"comp.graphics\"]\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                  categories=categories, \n",
    "                                  shuffle=True)\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=categories, \n",
    "                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in twenty_train.target[:5]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = twenty_train.target\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and vectorize documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3, stop_words=\"english\").fit(twenty_train.data)\n",
    "X_train = vectorizer.transform(twenty_train.data)\n",
    "X_test = vectorizer.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nb_model = MultinomialNB(alpha=1.0).fit(X_train, y_train)\n",
    "y_hat_nb_test = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat_nb_test, \n",
    "                            target_names=twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_model = LogisticRegression(penalty=\"none\", \n",
    "                              multi_class=\"multinomial\",\n",
    "                              solver=\"lbfgs\").fit(X_train, y_train)\n",
    "y_hat_lr_test = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat_lr_test, \n",
    "                            target_names=twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with L2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr2_model = LogisticRegression(penalty=\"l2\", \n",
    "                               solver=\"lbfgs\",\n",
    "                               multi_class=\"multinomial\",\n",
    "                               max_iter=1000,\n",
    "                               C=10).fit(X_train, y_train)\n",
    "y_hat_lr2_test = lr2_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat_lr2_test, \n",
    "                            target_names=twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of train/test performance across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\"Naive Bayes\": nb_model,\n",
    "              \"Logistic Regression\": lr_model,\n",
    "              \"L2 Regularized LR\": lr2_model}\n",
    "plot_data = []\n",
    "for name, model in model_info.items():\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    plot_data.append([name, \"Train\", train_acc])\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    plot_data.append([name, \"Test\", test_acc])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.ylim((0.9,1))\n",
    "plot_df = pd.DataFrame(plot_data, columns=[\"model\", \"dataset\", \"accuracy\"])\n",
    "sns.lineplot(data=plot_df, \n",
    "             sort=False,\n",
    "             x=\"dataset\", \n",
    "             y=\"accuracy\", \n",
    "             hue=\"model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "vocab = {idx: w for w, idx in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_data = {}\n",
    "for i, c in enumerate(twenty_train.target_names):\n",
    "    top_features = np.argsort(nb_model.feature_log_prob_[i,:])[-1:-11:-1]\n",
    "    logprobs = nb_model.feature_log_prob_[i,top_features]\n",
    "    words = [vocab[x] for x in top_features]\n",
    "    word_data[f\"{c}_P(w|c)\"] = [np.exp(x) for x in logprobs]\n",
    "    word_data[f\"{c}_words\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_data).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_data = {}\n",
    "for i, c in enumerate(twenty_train.target_names):\n",
    "    top_features = np.argsort(lr2_model.coef_[i,:])[-1:-11:-1]\n",
    "    coefs = lr2_model.coef_[i,top_features]\n",
    "    words = [vocab[x] for x in top_features]\n",
    "    word_data[f\"{c}_beta\"] = coefs\n",
    "    word_data[f\"{c}_words\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
